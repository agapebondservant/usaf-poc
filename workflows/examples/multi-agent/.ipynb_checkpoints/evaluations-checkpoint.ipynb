{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d18c4b68-e3ed-4729-9cf7-03ab3b189d2e",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; border: 1px solid gray; padding: 3px\">\n",
    "    <h3>Code Spec Evaluation</h3>\n",
    "    The following is an overview of the workflow:\n",
    "    <ul>\n",
    "    <li>Uses <b>DeepEval</b> to evaluate the code specifications doc</li>\n",
    "    <li>Uses specification generated by gpt-oss-20b as reference set</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db4641ed-d7a7-44d4-b367-eb948813c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Imports\n",
    "##############################################\n",
    "import os\n",
    "import traceback\n",
    "from openai import OpenAI\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "from deepeval import assert_test, evaluate\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval.metrics import GEval, AnswerRelevancyMetric\n",
    "from evaluate import load\n",
    "from deepeval.metrics import ArenaGEval\n",
    "from deepeval.test_case import ArenaTestCase\n",
    "from deepeval import compare\n",
    "import utils\n",
    "import nltk\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6edaa286-8e28-4326-9c67-1cb1c403ec63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /opt/app-\n",
      "[nltk_data]     root/src/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /opt/app-\n",
      "[nltk_data]     root/src/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /opt/app-\n",
      "[nltk_data]     root/src/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /opt/app-\n",
      "[nltk_data]     root/src/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /opt/app-\n",
      "[nltk_data]     root/src/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /opt/app-\n",
      "[nltk_data]     root/src/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "# Set Up Metric Instances\n",
    "##############################################\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "bleu_metric = load(\"bleu\")\n",
    "rouge_metric = load(\"rouge\")\n",
    "meteor_metric = load(\"meteor\")\n",
    "bertscore_metric = load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35a6d95b-8a41-48d2-9d91-2059d34ed3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Utilities\n",
    "##############################################\n",
    "def get_file_content(filepath: str) -> str:\n",
    "    with open(filepath, \"r\") as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26dbec95-6691-4c0f-8a26-6cb9595b1e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Evaluator Tools\n",
    "##############################################\n",
    "class CustomLLM(DeepEvalBaseLLM):\n",
    "    def __init__(self, client, model_name):\n",
    "        self.client = client\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.client\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        return self.generate(prompt)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return self.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eed6eb2-a643-4aae-8b7e-d35307fabfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Referenc _Based Evaluation Methods\n",
    "##############################################\n",
    "def compute_reference_based_eval_scores(predictions, references):\n",
    "    def compute_bleu4_scores(predictions, references):\n",
    "        \"\"\"\n",
    "        Computes BLEU-4 Scores\n",
    "        \"\"\"\n",
    "        results = bleu_metric.compute(predictions=predictions, references=references)\n",
    "        return results[\"bleu\"]\n",
    "    \n",
    "    def compute_rouge_scores(predictions, references):\n",
    "        \"\"\"\n",
    "        Computes ROUGE Scores\n",
    "        \"\"\"\n",
    "        results = rouge_metric.compute(predictions=predictions, references=references)\n",
    "        return results[\"rougeL\"]\n",
    "    \n",
    "    def compute_meteor_scores(predictions, references):\n",
    "        \"\"\"\n",
    "        Computes METEOR Scores\n",
    "        \"\"\"\n",
    "        results = meteor_metric.compute(predictions=predictions, references=references)\n",
    "        return results[\"meteor\"]\n",
    "        \n",
    "    \n",
    "    def compute_bert_scores(predictions, references):\n",
    "        \"\"\"\n",
    "        Computes BERT Scores\n",
    "        \"\"\"\n",
    "        results = bertscore_metric.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "        return results[\"f1\"]\n",
    "\n",
    "    return {\n",
    "        \"bleu4\": compute_bleu4_scores(predictions, references),\n",
    "        \"rougel\": compute_rouge_scores(predictions, references),\n",
    "        \"meteor\": compute_meteor_scores(predictions, references),\n",
    "        \"bert\": compute_bert_scores(predictions, references)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afb5bb56-c3c4-4e98-bbe5-ded9813b9756",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Benchmark Evaluation Methods\n",
    "##############################################\n",
    "def compute_benchmark_eval_scores(app_name: str):\n",
    "    try:\n",
    "\n",
    "        csv_results_file = f\"spec/{app_name}/benchmark.csv\"\n",
    "\n",
    "        data = pd.read_csv(csv_results_file).fillna(\"\")\n",
    "        \n",
    "        records = data.to_dict(orient='records')\n",
    "\n",
    "        evaluatorLlm = CustomLLM(client = OpenAI(api_key=os.getenv('REFERENCE_LLM_TOKEN'),base_url=os.getenv('REFERENCE_LLM_API_BASE')),\n",
    "                              model_name = os.getenv(\"REFERENCE_LLM_ID\"))\n",
    "\n",
    "        test_cases = [LLMTestCase(input=str(record[\"baseline\"]), actual_output=str(record[\"candidate\"])) for record in records]\n",
    "\n",
    "        metrics = [AnswerRelevancyMetric(threshold=0.7, model=evaluatorLlm)]\n",
    "\n",
    "        results = evaluate(test_cases=test_cases, metrics=metrics)\n",
    "\n",
    "        result_scores_relevancy = [metric.score for result in results.test_results for metric in result.metrics_data if metric.name==\"Answer Relevancy\"]\n",
    "\n",
    "        result_reasons_relevancy = [metric.reason for result in results.test_results for metric in result.metrics_data if metric.name==\"Answer Relevancy\"]\n",
    "\n",
    "        data[\"eval_scores_relevancy\"] = result_scores_relevancy\n",
    "\n",
    "        data[\"eval_reasons_relevancy\"] = result_reasons_relevancy\n",
    "\n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        traceback.print_exc()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7370445-ba8b-46c8-aae0-9bb7b2e87ee8",
   "metadata": {},
   "source": [
    "### Run Evaluations\n",
    "Run the evaluations pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ecf2ec1-756f-4b60-92b0-ee021b7aefdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluations_pipeline(git_repo: str):\n",
    "    try:\n",
    "\n",
    "        app_name = utils.get_unique_app_name_for_repo(git_repo)\n",
    "\n",
    "        results = compute_benchmark_eval_scores(app_name)\n",
    "\n",
    "        results.to_csv(f\"spec/{app_name}/benchmark_results.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "049e47be-df7b-41ec-bd0a-e7beb54e8372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using openai/gpt-oss-20b, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001B[38;2;106;0;255mAnswer Relevancy Metric\u001B[0m! \u001B[1;38;2;55;65;81m(\u001B[0m\u001B[38;2;55;65;81musing openai/gpt-oss-20b, \u001B[0m\u001B[38;2;55;65;81mstrict\u001B[0m\u001B[38;2;55;65;81m=\u001B[0m\u001B[3;38;2;55;65;81mFalse\u001B[0m\u001B[38;2;55;65;81m, \u001B[0m\n",
       "\u001B[38;2;55;65;81masync_mode\u001B[0m\u001B[38;2;55;65;81m=\u001B[0m\u001B[3;38;2;55;65;81mTrue\u001B[0m\u001B[1;38;2;55;65;81m)\u001B[0m\u001B[38;2;55;65;81m...\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ff6f5cfe7448d4b784d00931b4f03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 0.9090909090909091, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 0.91 because the output is largely relevant to the description of Golfap, but it includes an unrelated mention of a social score‚Äëkeeping and betting feature, which slightly lowers the overall relevancy., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Golfap is a lightweight **Golf News & Tournament** web application.\n",
      "* Surfaces a daily feed of golf headlines and related metadata (links, summaries, categories).\n",
      "* Provides a tournament‚Äëand‚Äëplayer overview, allowing users to inspect individual player statistics per event.\n",
      "* Uses ColdFusion Markup Language (CFML) with a **JSON** utility component for serializing query‚Äëresult sets to JSON for client‚Äëside consumption.\n",
      "Altogether the code collects, formats, and presents golf news, tournament leaderboards, and golfer performance data to a web browser.\n",
      "  - actual output: Golfap is a social golf score‚Äëkeeping web application that lets users track scores, place bets, and manage games with friends.  It presents news feeds, leaderboards, and PGA‚Äëtour tournament data, and it uses ColdFusion pages rendered from Markdown templates.  The application serialises data to JSON for AJAX calls, validates input, and integrates Google AdSense and Google Analytics for monetisation and tracking.  The code base is organised into a *news* module, a *pgatour* module, and a shared *tabs* component.  The application relies on a ColdFusion datasource named **GOLFAP** to query tournament, player, news, and score data.  The code is valid ColdFusion/Markdown and follows a typical MVC pattern with reusable templates and custom helper functions.  [Data: Reports (73, 173, 117, 175, 80)]\n",
      "\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 0.8571428571428571, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 0.86 because the answer correctly discusses Prototype, Scriptaculous, and a minimal portal widget framework, but includes an irrelevant mention of Firebug, which slightly lowers relevance., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Prototype, Scriptaculous and a minimal portal widget framework\n",
      "  - actual output: Prototype.js, Effects, Builder, DragDrop, Portal, Firebug, and custom JavaScript for dynamic UI updates.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the response fully addresses the request for navigation bar and header layout for both news and tournament sites, with no irrelevant statements. Great job!, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: ‚ÄùNavigation bar and header layout for both news and tournament sites.‚Äù\n",
      "  - actual output: reusable tab navigation component.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚ùå Answer Relevancy (score: 0.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 0.00 because the response only contains statements about reusable header markup and OBJECT PAGE_TRACKER, neither of which address the inclusion of CSS or tabs.cfm as requested., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: ‚ÄùIncludes CSS and `tabs.cfm`; used by most pages.‚Äù\n",
      "  - actual output: reusable header markup, includes `OBJECT PAGE_TRACKER` for analytics.  \n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the output fully addresses the input with no irrelevant statements., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: ‚ÄùHome page for the news site; displays ads, date, and a widget container.\n",
      "  - actual output: landing page for the news section.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the response fully addresses the request and contains no irrelevant statements., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: ‚ÄùLeaderboard table for the tournaments site; displays a table of tournaments and  leaderboard placeholders.‚Äù\n",
      "  - actual output: enders global leaderboard tables.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚ùå Answer Relevancy (score: 0.3333333333333333, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 0.33 because the answer contains unrelated statements about page and analytics trackers, which do not address repeated content across news pages, limiting relevance., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: ‚ÄùRepeated content used across news pages.‚Äù\n",
      "  - actual output: wrapper page for news content, includes `PAGE_TRACKER` and `ANALYTICSTRACKER`\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the output directly addresses the input by describing the process of retrieving real news data, formatting it into an array of structures, JSON‚Äëencoding it, and outputting the result, with no irrelevant statements., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: ‚ÄùRetrieves real news data from the database, formats it to an array of structures, JSON‚Äëencodes it, and outputs the result.\"\n",
      "  - actual output: retrieves news items via `QGETNEWS_QUERY`\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the output fully addresses the input without any irrelevant statements., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: ‚ÄùSame as `getNews.cfm` but with a static mock query for testing.‚Äù\n",
      "  - actual output: provides mock news data for testing.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the response fully addresses the request with no irrelevant content., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: ‚ÄùDemo forms showing how to collect user logins and client‚Äëside validation (Prototype).‚Äù\n",
      "  - actual output: handles user registration and group creation.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚ùå Answer Relevancy (score: 0.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 0.00 because the output includes a statement about debugging utilities for the news module, which is unrelated to the requested prototype‚Äëbased widget demo layout., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: ‚ÄùPrototype‚Äëbased widget demo layout.‚Äù\n",
      "  - actual output: debugging utilities for the news module.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the response directly addresses the input without any irrelevant statements, fully satisfying the request., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: ‚ÄùRedirects to the tournaments subsection.‚Äù\n",
      "  - actual output: landing page for PGA‚Äëtour data\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚ùå Answer Relevancy (score: 0.5, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 0.50 because the answer included a statement about analytics tracking, which is irrelevant to the requested header and navigation bar content, reducing relevance. However, the answer still partially addressed the header/navigation bar by providing some related content, so it is not lower than 0.50., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input:  ‚ÄúHeader and navigation bar specific to the tournaments section.‚Äù\n",
      "  - actual output: reusable header markup, includes `OBJECT PAGE_TRACKER` for analytics.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the response directly addresses the request, providing a clear explanation of how to create a main page that populates a `<select>` element and loads results via Ajax, with no irrelevant content., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: ‚ÄùMain page for selecting a tournament; populates a `<select>` and loads results via Ajax.‚Äù\n",
      "  - actual output: main tournament listing page.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚ùå Answer Relevancy (score: 0.5, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 0.50 because the output only included a heading 'JSON:' without providing the distinct tournament list, making it partially relevant but lacking the actual answer., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: ‚ÄùQuery for distinct tournament list used by the index page.‚Äù\n",
      "  - actual output: query helper for quick tournament data (`QTournaments`)\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚ùå Answer Relevancy (score: 0.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 0.00 because the output describes an AJAX endpoint that returns tournament details in JSON, which is unrelated to the requested server‚Äëside script that should return a tournament leaderboard table in HTML. This mismatch makes the answer entirely irrelevant, so the score cannot be higher., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: ‚ÄùServer‚Äëside script that returns a tournament leaderboard table in HTML.‚Äù\n",
      "  - actual output: AJAX endpoint returning tournament details in JSON.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚ùå Answer Relevancy (score: 0.5, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 0.50 because the output only contains a heading and does not provide any details about the server‚Äëside script, so it is partially relevant but lacks the substantive content needed to fully answer the request., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: ‚ÄùServer‚Äëside script that returns player history for a selected golfer.‚Äù\n",
      "  - actual output: AJAX endpoint returning player statistics in JSON.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the answer fully addresses the input with no irrelevant statements., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: ‚ÄúDropdown for selecting a golfer; loads individual golfer history via Ajax.‚Äù\n",
      "  - actual output: displays player profiles and statistics.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the answer fully addresses the input with no irrelevant content., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: ‚ÄúProvides news data for the tournaments sub‚Äësite.‚Äù\n",
      "  - actual output: retrieves news specific to tournaments.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the response fully addresses the request for an alternative navigation tab bar for the tournaments section without any irrelevant content., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: ‚ÄúAlternative navigation tab bar for the tournaments section.‚Äù\n",
      "  - actual output: tab navigation for tournament pages.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the response directly addresses the request by providing the requested utilities and contains no irrelevant statements., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input:  ‚ÄúProvides `encode`, `decode`, and schema `validate` utilities for JSON.\"\n",
      "  - actual output: provides `jsonEncode()` and `jsonDecode()`.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚ùå Answer Relevancy (score: 0.5833333333333334, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 0.58 because the answer included references to LeaderboardEntry, Bet, and Game, none of which are mentioned in the input, reducing overall relevance., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: - **User / Login** ‚Äì Represents a user login; mock logic in `encode.cfm`/`encode2.cfm`.\n",
      "- **Group** ‚Äì A collection of users; created in `encode.cfm`.\n",
      "- **News Feed** ‚Äì External RSS/Atom feeds providing golf news.\n",
      "- **Story** ‚Äì Individual news item with title, link, summary; table `tStories`.\n",
      "- **Category** ‚Äì Classification of stories (e.g., tournament, travel); table `tCategories`.\n",
      "- **Tournament** ‚Äì A golf event; joined data from `events`, `event_names`, `golfer_history`.\n",
      "- **Golfer** ‚Äì Player with first and last name; table `golfer`.\n",
      "- **GolferHistory** ‚Äì Performance records for a golfer in a specific tournament; table `golfer_history`.  \n",
      "  - actual output: - **User** ‚Äì represents a golfer or fan who can log in, track scores, place bets, and view news.\n",
      "- **Player** ‚Äì a golfer whose personal and performance data is stored in the `GOLFER` table and displayed via `pgatour/tournaments/players.md`.\n",
      "- **Tournament** ‚Äì an event defined in the `EVENTS` and `EVENT_NAMES` tables; accessed through `QTournaments` and displayed in `pgatour/tournaments/index.md`.\n",
      "- **NewsArticle** ‚Äì a news item stored in the `NEWS` table; retrieved by `QGETNEWS_QUERY` and rendered in `news/getNews.md`.\n",
      "- **LeaderboardEntry** ‚Äì aggregates a player's score for a tournament; displayed in `news/leaderboards.md`.\n",
      "- **Bet** ‚Äì a wager between users on a tournament outcome; implied by the application description but not explicitly modelled in the current code.\n",
      "- **Game** ‚Äì a collection of scores and bets for a session; implied by the application description but not explicitly modelled.\n",
      "\n",
      "The current state of the domain objects is that **Users** are created via `add_users.md`, **Players** and **Tournaments** are queried from the database and presented through AJAX endpoints, **NewsArticles** are fetched and displayed in the news section, and **LeaderboardEntries** are rendered from query results.  Bets and Games are not yet persisted in the code base.  \n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the response fully addressed the input without any irrelevant content., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: MySQL\n",
      "  - actual output: MySQL\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the answer fully addresses the input without any irrelevant statements., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: golfer master record\n",
      "  - actual output: stores golfer personal data.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the output fully addressed the input with no irrelevant statements., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: feeds metadata.\n",
      "  - actual output: stores news feed data.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the output directly addresses the category lookup request without including any irrelevant statements., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: category lookup.\n",
      "  - actual output: stores news categories.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the output fully addresses the input with no irrelevant content., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: stored news stories.\n",
      "  - actual output: stores news story data.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the response fully addressed the input without any irrelevant statements, providing a concise and relevant answer., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: performance histories.\n",
      "  - actual output: stores historical scores per golfer.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the output fully addresses the input with no irrelevant statements., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: tournament event data. \n",
      "  - actual output: stores tournament event records.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the response perfectly matches the request for human‚Äëreadable event names, with no irrelevant content. Great job!, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: human‚Äëreadable event names.\n",
      "  - actual output: maps event IDs to human‚Äëreadable names.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚ùå Answer Relevancy (score: 0.5, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 0.50 because the output included an irrelevant reference to 'ajax_getTourney.md', which does not relate to the requested file 'ajax_getPlayerData.cfm', reducing overall relevancy., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: - ajax_getPlayerData.cfm\n",
      "  - actual output: - ajax_getPlayerData.md\n",
      "- ajax_getTourney.md\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: openai/gpt-oss-20b, reason: The score is 1.00 because the output fully addresses the input with no irrelevant statements., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: \n",
      "  - actual output: \n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Answer Relevancy: 71.88% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001B[1;33m‚ö† WARNING:\u001B[0m No hyperparameters logged.\n",
       "¬ª \u001B]8;id=304957;https://deepeval.com/docs/evaluation-prompts\u001B\\\u001B[1;34mLog hyperparameters\u001B[0m\u001B]8;;\u001B\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">232.</span>35s | token cost: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71.88</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">23</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">9</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001B[38;2;5;245;141m‚úì\u001B[0m Evaluation completed üéâ! \u001B[1m(\u001B[0mtime taken: \u001B[1;36m232.\u001B[0m35s | token cost: \u001B[3;35mNone\u001B[0m USD\u001B[1m)\u001B[0m\n",
       "¬ª Test Results \u001B[1m(\u001B[0m\u001B[1;36m32\u001B[0m total tests\u001B[1m)\u001B[0m:\n",
       "   ¬ª Pass Rate: \u001B[1;36m71.88\u001B[0m% | Passed: \u001B[1;32m23\u001B[0m | Failed: \u001B[1;31m9\u001B[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001B[1;32m'deepeval view'\u001B[0m to analyze and save testing results on \u001B[38;2;106;0;255mConfident AI\u001B[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>prompt</th>\n",
       "      <th>baseline</th>\n",
       "      <th>candidate</th>\n",
       "      <th>eval_scores_relevancy</th>\n",
       "      <th>eval_reasons_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Provide a clear and concise explanation of the...</td>\n",
       "      <td>Golfap is a lightweight **Golf News &amp; Tourname...</td>\n",
       "      <td>Golfap is a social golf score‚Äëkeeping web appl...</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>The score is 0.91 because the output is largel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>What are the client-side frameworks used by th...</td>\n",
       "      <td>Prototype, Scriptaculous and a minimal portal ...</td>\n",
       "      <td>Prototype.js, Effects, Builder, DragDrop, Port...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>The score is 0.86 because the answer correctly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news/tabs.cfm</td>\n",
       "      <td>What is the responsibility of `news/tabs.cfm` ...</td>\n",
       "      <td>‚ÄùNavigation bar and header layout for both new...</td>\n",
       "      <td>reusable tab navigation component.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the response fully a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news/header.cfm</td>\n",
       "      <td>What is the responsibility of `news/header.cfm...</td>\n",
       "      <td>‚ÄùIncludes CSS and `tabs.cfm`; used by most pag...</td>\n",
       "      <td>reusable header markup, includes `OBJECT PAGE_...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>The score is 0.00 because the response only co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news/index.cfm</td>\n",
       "      <td>What is the responsibility of `news/index.cfm`...</td>\n",
       "      <td>‚ÄùHome page for the news site; displays ads, da...</td>\n",
       "      <td>landing page for the news section.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the output fully add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>news/leaderboards.cfm</td>\n",
       "      <td>What is the responsibility of `news/leaderboar...</td>\n",
       "      <td>‚ÄùLeaderboard table for the tournaments site; d...</td>\n",
       "      <td>enders global leaderboard tables.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the response fully a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>news/page.cfm</td>\n",
       "      <td>What is the responsibility of `news/page.cfm` ...</td>\n",
       "      <td>‚ÄùRepeated content used across news pages.‚Äù</td>\n",
       "      <td>wrapper page for news content, includes `PAGE_...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>The score is 0.33 because the answer contains ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>news/getNews.cfm</td>\n",
       "      <td>What is the responsibility of `news/getNews.cf...</td>\n",
       "      <td>‚ÄùRetrieves real news data from the database, f...</td>\n",
       "      <td>retrieves news items via `QGETNEWS_QUERY`</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the output directly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>news/getNews_mock.cfm</td>\n",
       "      <td>What is the responsibility of `news/getNews_mo...</td>\n",
       "      <td>‚ÄùSame as `getNews.cfm` but with a static mock ...</td>\n",
       "      <td>provides mock news data for testing.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the output fully add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>news/add_users.cfm</td>\n",
       "      <td>What is the responsibility of `news/add_users....</td>\n",
       "      <td>‚ÄùDemo forms showing how to collect user logins...</td>\n",
       "      <td>handles user registration and group creation.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the response fully a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>news/debug.cfm</td>\n",
       "      <td>What is the responsibility of `news/debug.cfm`...</td>\n",
       "      <td>‚ÄùPrototype‚Äëbased widget demo layout.‚Äù</td>\n",
       "      <td>debugging utilities for the news module.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>The score is 0.00 because the output includes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pgatour/index.cfm</td>\n",
       "      <td>What is the responsibility of `pgatour/index.c...</td>\n",
       "      <td>‚ÄùRedirects to the tournaments subsection.‚Äù</td>\n",
       "      <td>landing page for PGA‚Äëtour data</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the response directl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pgatour/tournaments/header.cfm</td>\n",
       "      <td>What is the responsibility of `pgatour/tournam...</td>\n",
       "      <td>‚ÄúHeader and navigation bar specific to the to...</td>\n",
       "      <td>reusable header markup, includes `OBJECT PAGE_...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>The score is 0.50 because the answer included ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pgatour/tournaments/index.cfm</td>\n",
       "      <td>What is the responsibility of `pgatour/tournam...</td>\n",
       "      <td>‚ÄùMain page for selecting a tournament; populat...</td>\n",
       "      <td>main tournament listing page.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the response directl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pgatour/tournaments/m_qtournaments.cfm</td>\n",
       "      <td>What is the responsibility of `pgatour/tournam...</td>\n",
       "      <td>‚ÄùQuery for distinct tournament list used by th...</td>\n",
       "      <td>query helper for quick tournament data (`QTour...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>The score is 0.50 because the output only incl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pgatour/tournaments/ajax_getTourney.cfm</td>\n",
       "      <td>What is the responsibility of `pgatour/tournam...</td>\n",
       "      <td>‚ÄùServer‚Äëside script that returns a tournament ...</td>\n",
       "      <td>AJAX endpoint returning tournament details in ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>The score is 0.00 because the output describes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pgatour/tournaments/ajax_getPlayerData.cfm</td>\n",
       "      <td>What is the responsibility of `pgatour/tournam...</td>\n",
       "      <td>‚ÄùServer‚Äëside script that returns player histor...</td>\n",
       "      <td>AJAX endpoint returning player statistics in J...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>The score is 0.50 because the output only cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pgatour/tournaments/players.cfm</td>\n",
       "      <td>What is the responsibility of `pgatour/tournam...</td>\n",
       "      <td>‚ÄúDropdown for selecting a golfer; loads indivi...</td>\n",
       "      <td>displays player profiles and statistics.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the answer fully add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pgatour/tournaments/getNews.cfm</td>\n",
       "      <td>What is the responsibility of `pgatour/tournam...</td>\n",
       "      <td>‚ÄúProvides news data for the tournaments sub‚Äësi...</td>\n",
       "      <td>retrieves news specific to tournaments.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the answer fully add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pgatour/tournaments/tabs.cfm</td>\n",
       "      <td>What is the responsibility of `pgatour/tournam...</td>\n",
       "      <td>‚ÄúAlternative navigation tab bar for the tourna...</td>\n",
       "      <td>tab navigation for tournament pages.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the response fully a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>news/json.cfc</td>\n",
       "      <td>What is the responsibility of `json.cfc` in th...</td>\n",
       "      <td>‚ÄúProvides `encode`, `decode`, and schema `val...</td>\n",
       "      <td>provides `jsonEncode()` and `jsonDecode()`.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the response directl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td>Provide a concise outline of the conceptual do...</td>\n",
       "      <td>- **User / Login** ‚Äì Represents a user login; ...</td>\n",
       "      <td>- **User** ‚Äì represents a golfer or fan who ca...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>The score is 0.58 because the answer included ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td>What kind of database is used for this applica...</td>\n",
       "      <td>MySQL</td>\n",
       "      <td>MySQL</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the response fully a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td>What is the purpose of the golfer table in the...</td>\n",
       "      <td>golfer master record</td>\n",
       "      <td>stores golfer personal data.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the answer fully add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td></td>\n",
       "      <td>What is the purpose of the tFeeds table in the...</td>\n",
       "      <td>feeds metadata.</td>\n",
       "      <td>stores news feed data.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the output fully add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td></td>\n",
       "      <td>What is the purpose of the tCategories table i...</td>\n",
       "      <td>category lookup.</td>\n",
       "      <td>stores news categories.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the output directly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td>What is the purpose of the tStories table in t...</td>\n",
       "      <td>stored news stories.</td>\n",
       "      <td>stores news story data.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the output fully add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "      <td>What is the purpose of the golfer_history tabl...</td>\n",
       "      <td>performance histories.</td>\n",
       "      <td>stores historical scores per golfer.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the response fully a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "      <td>What is the purpose of the events table in the...</td>\n",
       "      <td>tournament event data.</td>\n",
       "      <td>stores tournament event records.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the output fully add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td></td>\n",
       "      <td>What is the purpose of the event_names table i...</td>\n",
       "      <td>human‚Äëreadable event names.</td>\n",
       "      <td>maps event IDs to human‚Äëreadable names.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the response perfect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td></td>\n",
       "      <td>What are the AJAX endpoints used in the applic...</td>\n",
       "      <td>- ajax_getPlayerData.cfm</td>\n",
       "      <td>- ajax_getPlayerData.md\\n- ajax_getTourney.md</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>The score is 0.50 because the output included ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td></td>\n",
       "      <td>What is the entrypoint of the application?</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The score is 1.00 because the output fully add...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          code  \\\n",
       "0                                                \n",
       "1                                                \n",
       "2                                news/tabs.cfm   \n",
       "3                              news/header.cfm   \n",
       "4                               news/index.cfm   \n",
       "5                        news/leaderboards.cfm   \n",
       "6                                news/page.cfm   \n",
       "7                             news/getNews.cfm   \n",
       "8                        news/getNews_mock.cfm   \n",
       "9                           news/add_users.cfm   \n",
       "10                              news/debug.cfm   \n",
       "11                           pgatour/index.cfm   \n",
       "12              pgatour/tournaments/header.cfm   \n",
       "13               pgatour/tournaments/index.cfm   \n",
       "14      pgatour/tournaments/m_qtournaments.cfm   \n",
       "15     pgatour/tournaments/ajax_getTourney.cfm   \n",
       "16  pgatour/tournaments/ajax_getPlayerData.cfm   \n",
       "17             pgatour/tournaments/players.cfm   \n",
       "18             pgatour/tournaments/getNews.cfm   \n",
       "19                pgatour/tournaments/tabs.cfm   \n",
       "20                               news/json.cfc   \n",
       "21                                               \n",
       "22                                               \n",
       "23                                               \n",
       "24                                               \n",
       "25                                               \n",
       "26                                               \n",
       "27                                               \n",
       "28                                               \n",
       "29                                               \n",
       "30                                               \n",
       "31                                               \n",
       "\n",
       "                                               prompt  \\\n",
       "0   Provide a clear and concise explanation of the...   \n",
       "1   What are the client-side frameworks used by th...   \n",
       "2   What is the responsibility of `news/tabs.cfm` ...   \n",
       "3   What is the responsibility of `news/header.cfm...   \n",
       "4   What is the responsibility of `news/index.cfm`...   \n",
       "5   What is the responsibility of `news/leaderboar...   \n",
       "6   What is the responsibility of `news/page.cfm` ...   \n",
       "7   What is the responsibility of `news/getNews.cf...   \n",
       "8   What is the responsibility of `news/getNews_mo...   \n",
       "9   What is the responsibility of `news/add_users....   \n",
       "10  What is the responsibility of `news/debug.cfm`...   \n",
       "11  What is the responsibility of `pgatour/index.c...   \n",
       "12  What is the responsibility of `pgatour/tournam...   \n",
       "13  What is the responsibility of `pgatour/tournam...   \n",
       "14  What is the responsibility of `pgatour/tournam...   \n",
       "15  What is the responsibility of `pgatour/tournam...   \n",
       "16  What is the responsibility of `pgatour/tournam...   \n",
       "17  What is the responsibility of `pgatour/tournam...   \n",
       "18  What is the responsibility of `pgatour/tournam...   \n",
       "19  What is the responsibility of `pgatour/tournam...   \n",
       "20  What is the responsibility of `json.cfc` in th...   \n",
       "21  Provide a concise outline of the conceptual do...   \n",
       "22  What kind of database is used for this applica...   \n",
       "23  What is the purpose of the golfer table in the...   \n",
       "24  What is the purpose of the tFeeds table in the...   \n",
       "25  What is the purpose of the tCategories table i...   \n",
       "26  What is the purpose of the tStories table in t...   \n",
       "27  What is the purpose of the golfer_history tabl...   \n",
       "28  What is the purpose of the events table in the...   \n",
       "29  What is the purpose of the event_names table i...   \n",
       "30  What are the AJAX endpoints used in the applic...   \n",
       "31         What is the entrypoint of the application?   \n",
       "\n",
       "                                             baseline  \\\n",
       "0   Golfap is a lightweight **Golf News & Tourname...   \n",
       "1   Prototype, Scriptaculous and a minimal portal ...   \n",
       "2   ‚ÄùNavigation bar and header layout for both new...   \n",
       "3   ‚ÄùIncludes CSS and `tabs.cfm`; used by most pag...   \n",
       "4   ‚ÄùHome page for the news site; displays ads, da...   \n",
       "5   ‚ÄùLeaderboard table for the tournaments site; d...   \n",
       "6          ‚ÄùRepeated content used across news pages.‚Äù   \n",
       "7   ‚ÄùRetrieves real news data from the database, f...   \n",
       "8   ‚ÄùSame as `getNews.cfm` but with a static mock ...   \n",
       "9   ‚ÄùDemo forms showing how to collect user logins...   \n",
       "10              ‚ÄùPrototype‚Äëbased widget demo layout.‚Äù   \n",
       "11         ‚ÄùRedirects to the tournaments subsection.‚Äù   \n",
       "12   ‚ÄúHeader and navigation bar specific to the to...   \n",
       "13  ‚ÄùMain page for selecting a tournament; populat...   \n",
       "14  ‚ÄùQuery for distinct tournament list used by th...   \n",
       "15  ‚ÄùServer‚Äëside script that returns a tournament ...   \n",
       "16  ‚ÄùServer‚Äëside script that returns player histor...   \n",
       "17  ‚ÄúDropdown for selecting a golfer; loads indivi...   \n",
       "18  ‚ÄúProvides news data for the tournaments sub‚Äësi...   \n",
       "19  ‚ÄúAlternative navigation tab bar for the tourna...   \n",
       "20   ‚ÄúProvides `encode`, `decode`, and schema `val...   \n",
       "21  - **User / Login** ‚Äì Represents a user login; ...   \n",
       "22                                              MySQL   \n",
       "23                               golfer master record   \n",
       "24                                    feeds metadata.   \n",
       "25                                   category lookup.   \n",
       "26                               stored news stories.   \n",
       "27                             performance histories.   \n",
       "28                            tournament event data.    \n",
       "29                        human‚Äëreadable event names.   \n",
       "30                           - ajax_getPlayerData.cfm   \n",
       "31                                                      \n",
       "\n",
       "                                            candidate  eval_scores_relevancy  \\\n",
       "0   Golfap is a social golf score‚Äëkeeping web appl...               0.909091   \n",
       "1   Prototype.js, Effects, Builder, DragDrop, Port...               0.857143   \n",
       "2                  reusable tab navigation component.               1.000000   \n",
       "3   reusable header markup, includes `OBJECT PAGE_...               0.000000   \n",
       "4                  landing page for the news section.               1.000000   \n",
       "5                   enders global leaderboard tables.               1.000000   \n",
       "6   wrapper page for news content, includes `PAGE_...               0.333333   \n",
       "7           retrieves news items via `QGETNEWS_QUERY`               1.000000   \n",
       "8                provides mock news data for testing.               1.000000   \n",
       "9       handles user registration and group creation.               1.000000   \n",
       "10           debugging utilities for the news module.               0.000000   \n",
       "11                     landing page for PGA‚Äëtour data               1.000000   \n",
       "12  reusable header markup, includes `OBJECT PAGE_...               0.500000   \n",
       "13                      main tournament listing page.               1.000000   \n",
       "14  query helper for quick tournament data (`QTour...               0.500000   \n",
       "15  AJAX endpoint returning tournament details in ...               0.000000   \n",
       "16  AJAX endpoint returning player statistics in J...               0.500000   \n",
       "17           displays player profiles and statistics.               1.000000   \n",
       "18            retrieves news specific to tournaments.               1.000000   \n",
       "19               tab navigation for tournament pages.               1.000000   \n",
       "20        provides `jsonEncode()` and `jsonDecode()`.               1.000000   \n",
       "21  - **User** ‚Äì represents a golfer or fan who ca...               0.583333   \n",
       "22                                              MySQL               1.000000   \n",
       "23                       stores golfer personal data.               1.000000   \n",
       "24                             stores news feed data.               1.000000   \n",
       "25                            stores news categories.               1.000000   \n",
       "26                            stores news story data.               1.000000   \n",
       "27               stores historical scores per golfer.               1.000000   \n",
       "28                   stores tournament event records.               1.000000   \n",
       "29            maps event IDs to human‚Äëreadable names.               1.000000   \n",
       "30      - ajax_getPlayerData.md\\n- ajax_getTourney.md               0.500000   \n",
       "31                                                                  1.000000   \n",
       "\n",
       "                               eval_reasons_relevancy  \n",
       "0   The score is 0.91 because the output is largel...  \n",
       "1   The score is 0.86 because the answer correctly...  \n",
       "2   The score is 1.00 because the response fully a...  \n",
       "3   The score is 0.00 because the response only co...  \n",
       "4   The score is 1.00 because the output fully add...  \n",
       "5   The score is 1.00 because the response fully a...  \n",
       "6   The score is 0.33 because the answer contains ...  \n",
       "7   The score is 1.00 because the output directly ...  \n",
       "8   The score is 1.00 because the output fully add...  \n",
       "9   The score is 1.00 because the response fully a...  \n",
       "10  The score is 0.00 because the output includes ...  \n",
       "11  The score is 1.00 because the response directl...  \n",
       "12  The score is 0.50 because the answer included ...  \n",
       "13  The score is 1.00 because the response directl...  \n",
       "14  The score is 0.50 because the output only incl...  \n",
       "15  The score is 0.00 because the output describes...  \n",
       "16  The score is 0.50 because the output only cont...  \n",
       "17  The score is 1.00 because the answer fully add...  \n",
       "18  The score is 1.00 because the answer fully add...  \n",
       "19  The score is 1.00 because the response fully a...  \n",
       "20  The score is 1.00 because the response directl...  \n",
       "21  The score is 0.58 because the answer included ...  \n",
       "22  The score is 1.00 because the response fully a...  \n",
       "23  The score is 1.00 because the answer fully add...  \n",
       "24  The score is 1.00 because the output fully add...  \n",
       "25  The score is 1.00 because the output directly ...  \n",
       "26  The score is 1.00 because the output fully add...  \n",
       "27  The score is 1.00 because the response fully a...  \n",
       "28  The score is 1.00 because the output fully add...  \n",
       "29  The score is 1.00 because the response perfect...  \n",
       "30  The score is 0.50 because the output included ...  \n",
       "31  The score is 1.00 because the output fully add...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "git_repo_param = os.getenv(\"PIPELINE_PARAM_GIT_REPO\", \"https://github.com/holtonma/cf_golfap.git\")\n",
    "enabled_param = os.getenv(\"PIPELINE_PARAM_ENABLED\", \"true\")\n",
    "if enabled_param == \"true\":\n",
    "    eval_results = evaluations_pipeline(git_repo_param)\n",
    "    eval_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
